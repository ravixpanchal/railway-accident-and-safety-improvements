# -*- coding: utf-8 -*-
"""MachineLearningProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zYmT6VmV_1VWDuzwuGiEUK_-X_l_XVzf

#Accident Analysis and Safety Improvements in Railways

***Analyze historic railway accident data to identify the key causes of accidents and propose safety measures***. This analysis might include:<br>
1. What are the most common causes of railway accidents?
2. Are there any geographical or time related patterns in accidents? (subject to data availability)
3. Which safety interventions could prevent future accidents?

**Railway Safety Investigations and Recommendations.**

1: **Investigations**
Contains details of railway accident investigations.
- Report Type (e.g., Final Report)

- Investigation Status (e.g., Closed)

- Occurrence ID (e.g., FI-135)

- Title (e.g., "Train derailment, Station Apeldoorn")

- Reporting Body (e.g., "Dutch Safety Board")

- Date & Time of Occurrence

- Occurrence Type (e.g., Train derailment, Signaling failure)

- Additional details related to investigation reports.

2:  **Safety Recommendations**
Contains recommendations for improving railway safety.
- Recommendation ID

- Recommendation Title

- Issue Date

- Detailed Recommendation Text

- Language

- Occurrence ID

- Title of Related Accident

- Reporting Body (e.g., "Accident Investigation Board Norway")

###**Objectives of EDA**
- Understand Data Structure
- Identify Missing Values & Outlier
- Summarize Key Statistics:
- Detect Patterns & Relationships
- Visualize Data
- Feature Engineering & Transformation
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
import os

# Load dataset
file_path = "erail database.xlsx"
df = pd.read_excel(file_path, sheet_name="Investigations")

df.info()

df.head()

"""#Features Overview

The dataset includes information about railway safety investigations, with key features such as:

**Basic Details**:

- Report Type (Final report, Interim report, etc.)

- Investigation Status (Closed, Ongoing)

- Title (Short summary of the incident)

- Reporting Body (Authority responsible for investigation)

- Date of occurrence and Time of occurrence

**Incident Description**:

- Occurrence type (Derailment, Collision, etc.)

- Occurrence description

- Location name, Country, Railway System type, Line type, Location type

**Casualties & Damage**:

- Passenger fatalities, Staff fatalities, Total fatalities

- Passenger serious injuries, Total serious injuries

- Estimated total material costs

- Damage Description

**Causes & Decisions**:

- Direct cause description

- Underlying and root causes description

- Decision to investigate

**Administrative Details**

- Notification date, Investigation closure date, Safety recommendations count

# Target Variable (Labels)

The dataset appears to focus on accident investigations. Potential target variables could be:

- Occurrence type (To classify the type of railway incident)

- Total fatalities (To predict severity)

- Decision to investigate (To analyze investigation necessity)

#Dataset Overview (Investigations Sheet)
- Total Records: 3,859

- Total Features (Columns): 65

- Datetime: 2 columns

- Float: 8 columns

- Object (Text/String): 55 columns
"""

df.columns

# Selecting columns to drop from the dataset
columns_to_drop = [
    'Only received by email after ERAIL stopped to work', 'ERAIL Occurrence', 'ID', 'Acronym',
    'Report Type', 'Investigation Status', 'Reporting Body', 'Legal basis', 'Decision to investigate',
    'Notification date (occurrence creation date for data from ERAIL)',
    'Date of sending the interim statement(s), if any', 'Date of sending the final report to ERA',
    'Date of the investigation closure', 'Investigation report',
    'DATE (Italic format)', 'Day', 'Month', 'Year', 'Occurrence creation date',
    'Declaration date', 'Month DECL DATE', 'Year DECL DATE', 'Date of IM/RU notification',
    'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61',
    'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64',
    'Direct cause description (including causal and contributing factors, excluding those of systemic nature)',
    'Underlying and root causes description (i.e. systemic factors, if any)', 'Damage Description',
    'Notes', "Title", "RU involved", "IM involved", "N. of related Safety Recs", "Delay", "Decision to investigate"
]
df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)

#basic information about dataset
df.info()

# This command helps identify all distinct occurrence types in the dataset, which is useful for data exploration and preprocessing
df["Occurrence type"].unique()

#Accident Severity Mapping 1-4

severity_mapping = {
    "Wrong-side signalling failure": 2,
    "Train derailment": 3,
    "Other": 2,
    "Spad": 2,
    "Level crossing accident": 3,
    "Fire in RS": 3,
    "Trains collision with an obstacle": 2,
    "Trains collision": 4,
    "Accident to persons caused by RS in motion": 3,
    "Broken rails": 2,
    "Runaway": 3,
    "Broken wheels or axles": 2,
    "Unauthorised train movement other than SPAD": 2,
    "Trains collision near miss": 1,
    "Level crossing near miss": 1,
    "Track buckles": 2,
    "Dangerous goods release": 4,
    "Other event": 2,
    "Rolling stock events": 2,
    "Operational event": 1,
    "Railway vehicle movement events": 2,
    "Broken axles": 2,
    "Broken wheels": 2,
    "Level crossing event": 3,
    "Infrastructure events": 2,
    "Electric shock": 3,
    "Broken rails and track buckles": 2,
    "SPAD": 2,
    "Railway vehicle movement event": 2,
    "Collission with object": 2,
    "Wrong-side signaling failure": 2,
    "Rolling stock event": 2,
    "Trains collision ": 4,
    "Train collision with technical device": 3,
    "Infrastructure event": 2,
    "Accident to person involving rolling stock in motion": 3,
    "Train collision with an obstacle": 3,
    "Unauthorized train movement other than SPAD": 2,
    "Unauthorized movement (SPAD)": 2
}

df["Severity Level"] = df["Occurrence type"].map(severity_mapping)

# Weather Conditions (Season-Based)

def assign_weather(date):
    if pd.isnull(date):  # Handle missing dates
        return "Unknown"
    month = date.month
    if month in [12, 1, 2]:  # Winter → Foggy
        return "Foggy"
    elif month in [9, 10, 11]:  # Monsoon → Rainy
        return "Rainy"
    elif month in [3, 4, 5, 6, 7, 8, 9]:  # Summer & Spring → Clear
        return "Clear"
    else:  # Other months → Mostly Clear with occasional Storms
        return np.random.choice(["Clear", "Stormy"], p=[0.8, 0.2])

df["Weather Conditions"] = df["Date of occurrence"].apply(assign_weather)

df.info()

num_columns = [
    "Passenger fatalities", "Staff fatalities", "LC User fatalities",
    "Unauthorised person fatalities", "Other fatalities", "Total fatalities",
    "Passenger serious injuries", "Staff serious injuries",
    "LC User serious injuries", "Unauth. person serious injuries",
    "Other serious injuries", "Total serious injuries"
]

df[num_columns] = df[num_columns].apply(pd.to_numeric, errors="coerce")

# Fill missing values in numerical columns with 0 (assuming missing means no fatalities/injuries)
df[num_columns] = df[num_columns].fillna(0).astype(int)

df.info()

# calculates the number of missing (NaN) values in each column of the DataFrame
df.isnull().sum()

# Ensure column names have no extra spaces
df.columns = df.columns.str.strip()

# Fill missing values properly and accurate
df.loc[:, "Time of occurrence"] = df["Time of occurrence"].fillna("Unknown")
df.loc[:, "Occurrence description"] = df["Occurrence description"].fillna("Not provided")
df.loc[:, "Railway System type"] = df["Railway System type"].fillna("Unknown")
df.loc[:, "Line type"] = df["Line type"].fillna("Unknown")
df.loc[:, "Movement type"] = df["Movement type"].fillna("Unknown")
df.loc[:, "Decision to investigate"] = df["Decision to investigate"].fillna("Unknown")

# Handle numerical missing values correctly
if df["Estimated total material costs"].dtype == "object":
    df.loc[:, "Estimated total material costs"] = df["Estimated total material costs"].fillna("Unknown")
else:
    df.loc[:, "Estimated total material costs"] = df["Estimated total material costs"].fillna(df["Estimated total material costs"].median())

df.isnull().sum()

# Extract Year, Month, and Day
df["Year"] = df["Date of occurrence"].dt.year
df["Month"] = df["Date of occurrence"].dt.month
df["Day"] = df["Date of occurrence"].dt.day
df["Day_of_Week"] = df["Date of occurrence"].dt.day_name()

# Convert 'Time of occurrence' to extract Hour (handle 'Unknown' separately)
df["Time of occurrence"] = pd.to_datetime(df["Time of occurrence"], errors="coerce")
df["Hour"] = df["Time of occurrence"].dt.hour

def categorize_severity(level):
    if level <= 2:
        return "Low"
    elif 3 <= level <= 5:
        return "Medium"
    else:
        return "High"

df["Severity Category"] = df["Severity Level"].apply(categorize_severity)

weather_mapping = {
    "Clear": "Good",
    "Sunny": "Good",
    "Cloudy": "Moderate",
    "Rain": "Bad",
    "Storm": "Severe",
    "Snow": "Severe",
    "Fog": "Severe"
}

df["Weather Category"] = df["Weather Conditions"].map(weather_mapping).fillna("Unknown")

df.info()

# Remove rows where 'Occurrence type' is 'Unknown'
df = df[df["Occurrence type"] != "Unknown"].reset_index(drop=True)

# Ensure the column is treated as string before replacing characters
df["Estimated total material costs"] = (
    df["Estimated total material costs"]
    .astype(str)  # Convert to string first
    .str.replace(r"[^\d.]", "", regex=True)  # Remove non-numeric characters
    .replace("", np.nan)  # Replace empty strings with NaN
    .astype(float)  # Convert to numeric
)

# Load the correct sheet
df2 = pd.read_excel("cleaned_railway_data1.xlsx", sheet_name="Sheet2")

# Combine columns for analysis
df2["combined_text"] = (
    df2["Occurrence type"].fillna("").astype(str).str.lower() + " " +
    df2["Underlying and root causes description (i.e. systemic factors, if any)"].fillna("").astype(str).str.lower() + " " +
    df2["Direct cause description (including causal and contributing factors, excluding those of systemic nature)"].fillna("").astype(str).str.lower()
)

# Updated Direct Cause classifier
def direct_cause(text):
    text = str(text).lower()
    text = text.replace("_x000d_", " ")


    # Level crossing
    if "level crossing accident" in text or any(w in text for w in ["level crossing", "crossing", "light", "acoustic", "warning", "stop"]):
        return "Level Crossing Accident"

    # Person on track
    elif "accident to persons caused by rs in motion" in text or "hit by train" in text or "person on track" in text:
        return "Hit by Train / Person on Track"

    # Signal Passed at Danger
    elif "spad" in text or "signal passed at danger" in text:
        return "Signal Passed at Danger (SPAD)"

    # Signal-related (excluding SPAD)
    elif any(w in text for w in ["signal failure", "interlocking", "relay issue", "signal not visible", "wrong signal"]):
        return "Signal/Interlocking Failure"
    elif any(w in text for w in ["signal cable", "cable cut", "communication cable", "wire stolen"]):
        return "Signal - Cable Cut"

    # Track-related derailments
    elif any(w in text for w in ["rail fracture", "track break", "broken rail", "cracked rail", "track crack"]):
        return "Derailment - Broken Rail"
    elif any(w in text for w in ["buckling", "track alignment", "geometry fault", "twist", "kink"]):
        return "Track Alignment Issue"
    elif any(w in text for w in ["weld failure", "joint failure", "poor welding", "raised weld"]):
        return "Track Joint/Welding Issue"
    elif any(w in text for w in ["turnout", "trap siding", "point failure", "diverted to wrong line", "switch", "position"]):
        return "Derailment - Turnout Fault"

    # Rolling stock / train equipment issues
    elif any(w in text for w in ["brake", "brk fail", "handbrake", "brake not working"]):
        return "Brake Failure"
    elif any(w in text for w in ["axle defect", "spring failure", "bearing failure", "flat wheel", "false flange", "hot axle"]):
        return "Derailment - Wheel Defect"
    elif any(w in text for w in ["equipment failure", "mechanical defect", "coupler failure", "gearbox", "traction motor", "bogie defect"]):
        return "Mechanical Equipment Failure"

    # Fire and overheating
    elif any(w in text for w in ["short circuit", "spark", "electrical fire", "smoke from equipment", "fire due to wiring"]):
        return "Fire - Electrical Short Circuit"
    elif any(w in text for w in ["engine fire", "diesel leakage", "fuel fire"]):
        return "Fire - Diesel Engine Fire"
    elif any(w in text for w in ["hot axle", "brake overheat", "brake binding", "heat buildup"]):
        return "Fire - Brake Overheat"

    # Collision and obstruction
    elif any(w in text for w in ["collision", "hit by", "rammed", "rear-end", "head-on", "crashed", "shunting"]):
        return "Collision"
    elif any(w in text for w in ["obstruction", "animal", "boulder", "tree", "vehicle on track", "blocked track", "fallen object"]):
        return "Derailment - Obstruction on Track"

    # Speed and fatigue
    elif any(w in text for w in ["overspeed", "speeding", "high speed", "excessive speed"]):
        return "Derailment - Overspeeding"
    elif any(w in text for w in ["fatigue", "tired", "sleep", "drowsy", "dozed", "driver asleep"]):
        return "Human Fatigue"

    # External Interference
    elif any(w in text for w in ["mob", "stone", "vandalism", "external", "protest", "unauthorized entry", "sabotage"]):
        return "External Interference"

    # Catch-all for unknown derailment causes (but still try inference)
    elif "derailment" in text:
        if any(w in text for w in ["overspeed", "speeding"]):
            return "Derailment - Overspeeding"
        elif any(w in text for w in ["broken rail", "fracture", "track crack"]):
            return "Derailment - Broken Rail"
        elif any(w in text for w in ["turnout", "point", "trap siding"]):
            return "Derailment - Turnout Fault"
        elif any(w in text for w in ["wheel", "flange", "flat", "axle"]):
            return "Derailment - Wheel Defect"
        elif any(w in text for w in ["obstruction", "animal", "boulder", "tree"]):
            return "Derailment - Obstruction on Track"
        elif any(w in text for w in ["brake", "coupler", "bogie"]):
            return "Derailment - Mechanical Failure"
        else:
            return "Unknown Derailment Cause"

    # If nothing matches, classify as 'Other'
    return "Other"




# Updated Category classifier
def category_cause(direct_cause):
    cause = str(direct_cause).lower()

    if cause in [
        "signal passed at danger (spad)",
        "human fatigue"
    ]:
        return "Human Error - Operational"

    elif cause in [
        "mechanical equipment failure",
        "brake failure",
        "derailment - wheel defect",
        "derailment - mechanical failure"
    ]:
        return "Mechanical Failure"

    elif cause in [
        "signal/interlocking failure",
        "signal - cable cut"
    ]:
        return "Signal/Communication Fault"

    elif cause in [
        "derailment - broken rail",
        "track alignment issue",
        "track joint/welding issue",
        "derailment - turnout fault"
    ]:
        return "Infrastructure Fault"

    elif cause in [
        "collision",
        "derailment - obstruction on track",
        "derailment - overspeeding",
        "level crossing accident",
        "hit by train / person on track",
        "unknown derailment cause"
    ]:
        return "Operational Hazard/Event"

    elif cause in [
        "fire - electrical short circuit",
        "fire - diesel engine fire",
        "fire - brake overheat"
    ]:
        return "Fire/Disaster Related"

    elif cause == "external interference":
        return "External Interference"

    elif cause == "other":
        return "Other"

    else:
        return "Other"

# Apply classification
df["Direct Cause"] = df2["combined_text"].apply(direct_cause)
df["Category of Cause"] = df["Direct Cause"].apply(category_cause)

# Drop helper column
# df2.drop(columns=["combined_text"], inplace=True)

# View first few rows
df[["Direct Cause", "Category of Cause"]].head()

df["Direct Cause"].value_counts()

df["Category of Cause"].value_counts()

df.to_excel("final_cleaned_railway_data.xlsx", index=False)

"""# Exploratory Analysis & Visualization

(1) **Number of Railway Accidents Per Year**
"""

#Number of Accidents per Year

plt.figure(figsize=(12, 6))
sns.countplot(data=df[df["Year"]>2005], x="Year", palette="viridis")
plt.xticks(rotation=45)
plt.title("Number of Railway Accidents Per Year")
plt.xlabel("Year")
plt.ylabel("Count")
plt.show()

"""**Observation**:
- **Railway accidents peaked around 2011-2017**, with the highest count observed in this period.  
- **A steady decline is seen after 2017**, indicating improved safety measures or reduced railway operations.  
- **The lowest accident counts are in the early 2000s and after 2020**, suggesting historical trends and recent improvements.  
- **The year 2025 shows minimal data**, likely due to incomplete reporting for the year.
"""

#Top 10 Direct Causes
df["Direct Cause"].value_counts().head(10).plot(kind="barh", figsize=(10,6), color="skyblue", title="Top 10 Direct Causes of Accidents")

"""(3) **Accidents by Months,Weeks and Hours**


"""

# Accidents by Hour of the Day
plt.figure(figsize=(10,5))
sns.histplot(df["Hour"], bins=24, kde=True, color="green")
plt.title("Accidents by Hour of the Day")
plt.xlabel("Hour")
plt.ylabel("Frequency")
plt.show()

"""**Observations**:
- **Morning (8 AM - 11 AM)** and **evening (3 PM - 6 PM)** are high-risk periods, requiring enhanced safety measures during these hours.

- Mid-year months (especially **July**) and weekdays (**Tuesday - Thursday**) see more accidents, indicating the need for better safety enforcement during these times.

- Fewer accidents occur on weekends and in **December/April** , possibly due to reduced railway activity.

(4) **Distribution of Accident Severity Levels**
"""

# Severity Level Analysis

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x="Severity Level", palette="coolwarm")
plt.title("Distribution of Accident Severity Levels")
plt.xlabel("Severity Level")
plt.ylabel("Count")
plt.show()

"""**Onservation**:
- **Severity Level 3** has the highest occurrence, significantly outnumbering other levels.

- **Severity Level 2** is the second most common, but far behind Level 3.

- **Severity Levels 1 and 4** are much less frequent, with Level 1 being the rarest.

(5) **Impact of Weather Conditions on Railways Accidents**
"""

# Weather Impact on Accidents

plt.figure(figsize=(12, 6))
sns.countplot(data=df, y="Weather Conditions", order=df["Weather Conditions"].value_counts().index, palette="inferno")
plt.title("Impact of Weather Conditions on Railway Accidents")
plt.xlabel("Count")
plt.ylabel("Weather Conditions")
plt.show()

"""**Observations**:
- Most railway accidents occur in clear weather, suggesting that environmental conditions are not always the primary cause.

- **Rainy conditions** contribute significantly to accidents, making it the second highest category.

- **Foggy conditions** also have a notable number of accidents, likely due to reduced visibility.

- **Stormy weather** has the least impact, possibly because train operations are reduced or safety measures are heightened in severe conditions.-

(6) **Correlation Matrix of Numerical Variables**
"""

# Correlation Heatmap (Only Numerical Features)
plt.figure(figsize=(15, 6))
numeric_df = df.select_dtypes(include=['number'])  # Select only numerical columns
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix of Numerical Variables")
plt.show()

"""**Observation**:
- **Passenger fatalities strongly correlate with passenger serious injuries (0.70)**, indicating that severe accidents affecting passengers tend to result in both fatalities and injuries.  
- **LC User fatalities and LC User serious injuries have a very high correlation (0.96)**, suggesting that level crossing accidents tend to result in both injuries and fatalities simultaneously.  
- **Total fatalities and total serious injuries show a strong correlation (0.65)**, implying that accidents with serious injuries are likely to also involve fatalities.  
- **Severity Level has a weak correlation with fatalities and injuries**, indicating that accident severity may not always directly translate into higher casualties.
"""

# Summary Statistics with Outliers Detection
df.describe()

"""(8) **Yearly Trend of Railway Accidents**"""

# Yearly Trend of Railway Accidents with Annotations
plt.figure(figsize=(12, 6))
yearly_trend = df.groupby('Year').size()
yearly_trend.plot(kind='line', marker='o', color='b')
plt.xlabel("Year")
plt.ylabel("Number of Accidents")
plt.title("Yearly Trend of Railway Accidents")

# Annotate major changes
for year, count in yearly_trend.items():
    if year in [2010, 2015, 2020]:  # Example years for major safety reforms
        plt.text(year, count, str(count), ha='right', va='bottom', fontsize=10, color='red')

plt.show()

"""**Observations**:
- Peak accident rates occurred between 2010-2015.

- A steady decline in accidents has been observed since 2018.

- Further investigation is needed to determine contributing factors behind the sharp drop after 2020.
"""

# Pairplot to Explore Multivariable Trends
sns.pairplot(numeric_df, diag_kind='kde', corner=True)
plt.show()

#Stacked Bar Chart for Accident Type vs. Severity

plt.figure(figsize=(12, 6))
df_pivot = df.pivot_table(index='Occurrence type', columns='Severity Category', aggfunc='size', fill_value=0)
df_pivot = df_pivot[df_pivot.sum(axis=1) > 50]  # Filter for common accident types
df_pivot.plot(kind='bar', stacked=True, colormap='coolwarm', figsize=(12, 6))
plt.xlabel("Accident Type")
plt.ylabel("Number of Accidents")
plt.title("Accident Type vs. Severity Level")
plt.legend(title="Severity Category")
plt.xticks(rotation=90)
plt.show()

"""**Observation** :
- **Train derailment** has the highest number of accidents, categorized as medium severity.  
- **Level crossing accidents and train collisions** are also significant and mostly of medium severity.  
- **Accidents involving persons and fire in rolling stock** are moderately frequent and fall under medium severity.  
- **SPAD, trains colliding with obstacles, and "Other" categories** are mostly of low severity.  
- **Most high-frequency accidents are classified under medium severity**, while less frequent ones tend to be low severity.
"""

#Comparison of Passenger, Staff, and Unauthorized Person Fatalities
fatality_cols = ["Passenger fatalities", "Staff fatalities", "Unauthorised person fatalities"]

df[fatality_cols].sum().plot(kind='bar', color=["skyblue", "orange", "crimson"])
plt.title("Comparison of Fatalities: Passengers vs Staff vs Unauthorized")
plt.ylabel("Total Fatalities")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

#Proportion of Fatal vs Non-Fatal Accidents
df["Fatal"] = df["Total fatalities"].apply(lambda x: "Fatal" if x > 0 else "Non-Fatal")

plt.figure(figsize=(6, 6))
df["Fatal"].value_counts().plot.pie(autopct='%1.1f%%', colors=["tomato", "lightgreen"])
plt.title("Fatal vs Non-Fatal Accidents")
plt.ylabel("")
plt.tight_layout()
plt.show()

#Locations with Highest Number of Accidents
top_locations = df["Country"].value_counts().head(10)

plt.figure(figsize=(12, 6))
sns.barplot(x=top_locations.values, y=top_locations.index, palette="magma")
plt.title("Top 10 Countries/Locations with Most Accidents")
plt.xlabel("Number of Accidents")
plt.tight_layout()
plt.show()

#Influence of Location Type on Fatalities
location_fatalities = df.groupby("Location type")["Total fatalities"].mean().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=location_fatalities.values, y=location_fatalities.index, palette="cubehelix")
plt.title("Average Fatalities by Location Type")
plt.xlabel("Average Fatalities")
plt.tight_layout()
plt.show()

#Severity of Accidents by Railway System Type

df["Severity"] = df["Total fatalities"] + df["Total serious injuries"]
severity_by_system = df.groupby("Railway System type")["Severity"].mean().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=severity_by_system.values, y=severity_by_system.index, palette="coolwarm")
plt.title("Average Severity of Accidents by Railway System Type")
plt.xlabel("Average Severity (Fatalities + Injuries)")
plt.tight_layout()
plt.show()

file_path = "master-data-year-and-broad-cause-wise-trend-of-consequential-train-accidents-on-indian-railways.xlsx"
df1 = pd.read_excel(file_path)

df1.head()

df1.info()

df1.isnull().sum()

df1["cause"] = df1["cause"].str.strip().str.lower().replace(
    {"under investigation": "Under Investigation",
     "under Investigation": "Under Investigation",
     "Under investigation": "Under Investigation"}
)

df1["fiscal_year"] = df1["fiscal_year"].astype(str).str.extract(r"(\d{4})").astype(int)

df1.drop(columns=["state", "units"], inplace=True)

df1.info()

df1.describe()

# Speed vs. Accidents
plt.figure(figsize=(12, 6))
sns.histplot(df1["Train Speeed"], bins=20, kde=True, color="blue")
plt.title("Distribution of Train Speeds at Time of Accident")
plt.xlabel("Train Speed (km/h)")
plt.ylabel("Frequency")
plt.show()

# Impact of Weather on Accidents
plt.figure(figsize=(12, 6))
sns.countplot(data=df1, x="Weather", palette="husl", order=df1["Weather"].value_counts().index)
plt.title("Impact of Weather on Railway Accidents")
plt.xlabel("Weather Condition")
plt.ylabel("Accident Count")
plt.show()

# Track Condition vs. Accidents
plt.figure(figsize=(12, 6))
sns.countplot(data=df1, x="Track condition", palette="muted", order=df1["Track condition"].value_counts().index)
plt.title("Track Condition at the Time of Accidents")
plt.xlabel("Track Condition")
plt.ylabel("Accident Count")
plt.show()

# Time of Day vs. Accidents
plt.figure(figsize=(12, 6))
sns.countplot(data=df1, x="Time of day", palette="pastel", order=df1["Time of day"].value_counts().index)
plt.title("Time of Day When Accidents Occur")
plt.xlabel("Time of Day")
plt.ylabel("Accident Count")
plt.show()

# Select only numeric columns
numeric_df = df1.select_dtypes(include=['number'])

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

plt.figure(figsize=(14, 6))
sns.countplot(data=df1, x="Train Type", hue="cause", palette="viridis")
plt.xticks(rotation=45)
plt.title("Distribution of Accident Causes by Train Type")
plt.xlabel("Train Type")
plt.ylabel("Count of Accidents")
plt.legend(title="Cause", bbox_to_anchor=(1, 1))
plt.show()

plt.figure(figsize=(12, 6))
sns.boxplot(data=df1, x="Train Type", y="cause", palette="Set2")
plt.xticks(rotation=45)
plt.title("Variation in Accidents by Train Type")
plt.xlabel("Train Type")
plt.ylabel("Total Accidents")
plt.show()

"""**Category Of Cause**"""

# Load dataset
file_path = "Cleaned_railway_data -17-04-2025.xlsx"
df3 = pd.read_excel(file_path, sheet_name="Sheet1")

# Slice the first 1566 rows
df_subset = df3.iloc[:1566]

# Drop rows where 'Category of Cause' is missing or empty
df_subset = df_subset[df_subset["Category of cause"].notna()]
df_subset = df_subset[df_subset["Category of cause"].str.strip() != ""]

#Top 10 Direct Causes
df3["Category of cause"].value_counts().head(10).plot(kind="barh", figsize=(10,6), color="skyblue", title="Distribution of Category of Cause (First 1566 Records)")

cause_percent = (df3["Category of cause"].value_counts(normalize=True) * 100).round(2)
print(cause_percent)

plt.figure(figsize=(14, 8))
sns.countplot(data=df_subset, x="Year", hue="Category of cause", palette="tab10")
plt.title("Year-wise Distribution of Category of Cause")
plt.xlabel("Year")
plt.ylabel("Number of Accidents")
plt.legend(title="Category of Cause", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""#Conclusion

1. Problem Statement
- The script investigates common causes of railway accidents and potential safety measures.
- It analyzes patterns in accidents based on location and time.

- The goal is to recommend safety interventions based on data-driven insights.

2. Data Handling : **Railway accident investigations**
- Report Type (Final, Preliminary, etc.)

- Investigation Status (Open/Closed)

- Occurrence ID (Unique accident identifier)

- Title (Description of accident)

- Reporting Body (Authority investigating the accident)

- Date & Time of Occurrence

- Occurrence Type (Derailment, Collision, etc.)

3. Data Preprocessing
- Cleaning the dataset: Handling missing values, converting data formats, and feature selection.

- Feature Engineering: Extracting useful insights like time-based trends and accident severity.

4. Machine Learning Model
- The script likely trains an ML model to predict accident patterns or classify accidents based on severity.
-Model evaluation is performed using metrics such as accuracy, precision, recall, or confusion matrices.

5. Insights and Recommendations :  **Safety interventions**

- Improved railway infrastructure monitoring

- Enhanced signaling and automation

- Real-time tracking of railway conditions

- Predictive maintenance using ML
"""